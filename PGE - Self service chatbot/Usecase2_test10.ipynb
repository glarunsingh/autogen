{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from docx import Document as DocxDocument\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Load Environment Variables --------------------\n",
    "load_dotenv()\n",
    "\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "llm_model = os.getenv(\"LLM_MODEL\")\n",
    "\n",
    "if not all([api_version, endpoint, api_key, deployment_name, llm_model]):\n",
    "    raise ValueError(\"Some environment variables are missing. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Autogen LLM\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"config_list\": autogen.config_list_from_json(\"OAI_CONFIG_LIST\"),\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Define Helper Functions --------------------\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = DocxDocument(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    return \"\\n\".join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "def read_document(file_path):\n",
    "    if not file_path or not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    if file_path.endswith(\".txt\"):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        return \"Unsupported file format. Please provide a valid TXT, DOCX, or PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Define Individual Agents for Each Section --------------------\n",
    "\n",
    "wbs_agent = AssistantAgent(\n",
    "    name=\"wbs_agent\",\n",
    "    system_message=\"You are gathering details for Work Breakdown Structure (WBS) and effort estimation. Please ask questions to clarify and gather all relevant data.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "assumptions_agent = AssistantAgent(\n",
    "    name=\"assumptions_agent\",\n",
    "    system_message=\"You are gathering assumptions related to the project. Ask detailed questions to clarify and collect all assumptions that will affect project planning.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "resource_cost_agent = AssistantAgent(\n",
    "    name=\"resource_cost_agent\",\n",
    "    system_message=\"You are gathering resource cost estimation. Ask detailed questions about the resources required, their costs, and relevant financial details.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "tech_stack_cost_agent = AssistantAgent(\n",
    "    name=\"tech_stack_cost_agent\",\n",
    "    system_message=\"You are gathering details on tech stack costs. Ask questions about the technologies planned for this project and their associated costs.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "infrastructure_cost_agent = AssistantAgent(\n",
    "    name=\"infrastructure_cost_agent\",\n",
    "    system_message=\"You are gathering infrastructure cost details. Ask questions to clarify the infrastructure needed and the associated costs.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "total_ownership_cost_agent = AssistantAgent(\n",
    "    name=\"total_ownership_cost_agent\",\n",
    "    system_message=\"You are gathering total cost of ownership over three years. Ask questions on maintenance, support, and any recurring costs.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "excel_cost_estimation_agent = AssistantAgent(\n",
    "    name=\"excel_cost_estimation_agent\",\n",
    "    system_message=\"You are gathering detailed cost estimation information to create an Excel artifact. Ask questions to gather specific financial details.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "resource_types_agent = AssistantAgent(\n",
    "    name=\"resource_types_agent\",\n",
    "    system_message=\"You are identifying types of resources required for the project. Ask questions to specify the necessary resources.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_volume_agent = AssistantAgent(\n",
    "    name=\"user_volume_agent\",\n",
    "    system_message=\"You are estimating user volume and deployment scope. Ask questions to determine expected user demand and deployment requirements.\",\n",
    "    llm_config=llm_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------- Define User Proxy Agent --------------------\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m \u001b[43mUserProxyAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_proxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALWAYS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\817840\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\user_proxy_agent.py:92\u001b[0m, in \u001b[0;36mUserProxyAgent.__init__\u001b[1;34m(self, name, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, default_auto_reply, llm_config, system_message, description, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     34\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     45\u001b[0m ):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m        name (str): name of the agent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m            [ConversableAgent](conversable_agent#__init__).\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_execution_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_USER_PROXY_AGENT_DESCRIPTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m    109\u001b[0m         log_new_agent(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlocals\u001b[39m())\n",
      "File \u001b[1;32mc:\\Users\\817840\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:236\u001b[0m, in \u001b[0;36mConversableAgent.__init__\u001b[1;34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent)\u001b[0m\n\u001b[0;32m    234\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    235\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m decide_use_docker(use_docker)\n\u001b[1;32m--> 236\u001b[0m \u001b[43mcheck_can_use_docker_or_throw\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_docker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m use_docker\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_reply([Agent, \u001b[38;5;28;01mNone\u001b[39;00m], ConversableAgent\u001b[38;5;241m.\u001b[39mgenerate_code_execution_reply)\n",
      "File \u001b[1;32mc:\\Users\\817840\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogen\\code_utils.py:324\u001b[0m, in \u001b[0;36mcheck_can_use_docker_or_throw\u001b[1;34m(use_docker)\u001b[0m\n\u001b[0;32m    322\u001b[0m docker_installed_and_running \u001b[38;5;241m=\u001b[39m is_docker_running()\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inside_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m docker_installed_and_running:\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode execution is set to be run in docker (default behaviour) but docker is not running.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe options available are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Make sure docker is running (advised approach for code execution)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: False in code_execution_config\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set AUTOGEN_USE_DOCKER to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0/False/no\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in your environment variables\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    330\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables"
     ]
    }
   ],
   "source": [
    "# -------------------- Define User Proxy Agent --------------------\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Main Logic --------------------\n",
    "def process_document_or_summary(doc_path=None):\n",
    "    \"\"\"Process document or initiate with user-provided summary.\"\"\"\n",
    "    content = read_document(doc_path)\n",
    "\n",
    "    if content:\n",
    "        print(f\"\\nExtracted Content from '{doc_path}':\\n{content}\\n\")\n",
    "    else:\n",
    "        print(\"No document provided. Please enter a summary.\\n\")\n",
    "        content = input(\"Enter a summary of the process: \")\n",
    "\n",
    "    # Initiate chat with each agent sequentially, collecting responses\n",
    "    chat_results = user_proxy.initiate_chats([\n",
    "        {\n",
    "            \"recipient\": wbs_agent,\n",
    "            \"message\": content,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": assumptions_agent,\n",
    "            \"message\": \"Please gather project assumptions from this data.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": resource_cost_agent,\n",
    "            \"message\": \"Please estimate the resource costs for this project.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": tech_stack_cost_agent,\n",
    "            \"message\": \"Please gather tech stack costs for this project.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": infrastructure_cost_agent,\n",
    "            \"message\": \"Please estimate the infrastructure costs.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": total_ownership_cost_agent,\n",
    "            \"message\": \"Estimate the total cost of ownership over a three-year period.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": resource_types_agent,\n",
    "            \"message\": \"Identify types of resources required for this project.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": user_volume_agent,\n",
    "            \"message\": \"Estimate the expected user volume and deployment requirements.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": excel_cost_estimation_agent,\n",
    "            \"message\": \"Gather cost estimation details to create an Excel artifact.\",\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    # Display final collected and processed data\n",
    "    final_data = {\n",
    "        \"summary\": content,\n",
    "        \"WBS\": chat_results[0].chat_messages[-1][\"content\"],\n",
    "        \"Assumptions\": chat_results[1].chat_messages[-1][\"content\"],\n",
    "        \"Resource Cost\": chat_results[2].chat_messages[-1][\"content\"],\n",
    "        \"Tech Stack Cost\": chat_results[3].chat_messages[-1][\"content\"],\n",
    "        \"Infrastructure Cost\": chat_results[4].chat_messages[-1][\"content\"],\n",
    "        \"Total Ownership Cost\": chat_results[5].chat_messages[-1][\"content\"],\n",
    "        \"Excel Cost Estimation\": chat_results[6].chat_messages[-1][\"content\"],\n",
    "        \"Resource Types\": chat_results[7].chat_messages[-1][\"content\"],\n",
    "        \"User Volume\": chat_results[8].chat_messages[-1][\"content\"],\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Project Estimation:\\n\", json.dumps(final_data, indent=2))\n",
    "    return final_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No document provided. Please enter a summary.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_proxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     doc_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the document path (or press Enter to skip): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocess_document_or_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mprocess_document_or_summary\u001b[1;34m(doc_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a summary of the process: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initiate chat with each agent sequentially, collecting responses\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m chat_results \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241m.\u001b[39minitiate_chats([\n\u001b[0;32m     14\u001b[0m     {\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: wbs_agent,\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     },\n\u001b[0;32m     19\u001b[0m     {\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: assumptions_agent,\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease gather project assumptions from this data.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     },\n\u001b[0;32m     24\u001b[0m     {\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: resource_cost_agent,\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease estimate the resource costs for this project.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     },\n\u001b[0;32m     29\u001b[0m     {\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: tech_stack_cost_agent,\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease gather tech stack costs for this project.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     },\n\u001b[0;32m     34\u001b[0m     {\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: infrastructure_cost_agent,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease estimate the infrastructure costs.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m     },\n\u001b[0;32m     39\u001b[0m     {\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: total_ownership_cost_agent,\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimate the total cost of ownership over a three-year period.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     },\n\u001b[0;32m     44\u001b[0m     {\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: resource_types_agent,\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify types of resources required for this project.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     },\n\u001b[0;32m     49\u001b[0m     {\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_volume_agent,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimate the expected user volume and deployment requirements.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     },\n\u001b[0;32m     54\u001b[0m     {\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: excel_cost_estimation_agent,\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGather cost estimation details to create an Excel artifact.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection_with_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m     },\n\u001b[0;32m     59\u001b[0m ])\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Display final collected and processed data\u001b[39;00m\n\u001b[0;32m     62\u001b[0m final_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWBS\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mchat_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser Volume\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_results[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mchat_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     73\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_proxy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------- Execution --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    doc_path = input(\"Enter the document path (or press Enter to skip): \").strip()\n",
    "    process_document_or_summary(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
